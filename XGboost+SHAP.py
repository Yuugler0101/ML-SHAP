import pandas as pd
import numpy as np
import shap
import matplotlib.pyplot as plt
from xgboost import XGBRegressor, XGBClassifier
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import LabelEncoder
from sklearn.inspection import partial_dependence, PartialDependenceDisplay
import os
from scipy import stats
from matplotlib.patches import Rectangle

# ====================================
#         è®¾ç½®å­—ä½“ Times New Roman
# ====================================
plt.rcParams['font.family'] = 'Times New Roman'
plt.rcParams['axes.labelsize'] = 20
plt.rcParams['axes.titlesize'] = 14
plt.rcParams['xtick.labelsize'] = 15
plt.rcParams['ytick.labelsize'] = 15

# ====================================
#             è¯»å–æ•°æ®
# ====================================
df = pd.read_csv("ç†”æ± æ·±åº¦å’Œç²—ç³™åº¦.csv")

X = df.iloc[:, 0:3]  # åŠŸç‡ã€é€Ÿåº¦ã€æ¿€å…‰é—´éš”
y_depth = df.iloc[:, 3]
y_rough = df.iloc[:, 4]
y_pore = df.iloc[:, 5]

# åˆ†ç±»ç¼–ç 
le = LabelEncoder()
y_pore_encoded = le.fit_transform(y_pore)

# è·å–ç±»åˆ«åç§°
class_names = le.classes_
n_classes = len(class_names)
print(f"æ£€æµ‹åˆ° {n_classes} ä¸ªå­”éš™ç±»åˆ«: {class_names}")

# ====================================
#           XGB å‚æ•°
# ====================================
params = {
    "booster": "gbtree",
    "n_estimators": 100,
    "learning_rate": 0.1,
    "reg_alpha": 0,
    "reg_lambda": 1,
    "subsample": 1,
    "colsample_bytree": 1,
    "colsample_bynode": 1,
    "min_child_weight": 0,
    "max_depth": 8,
    "random_state": 0
}

# è¾“å‡ºç›®å½•
output_dir = "shap_output29"
os.makedirs(output_dir, exist_ok=True)


# =====================================================================
#                 åˆ†æICEå¼‚å¸¸ç‚¹çš„å‡½æ•°ï¼ˆæ”¹è¿›ç‰ˆï¼‰
# =====================================================================
def analyze_ice_anomalies(model, X, feature_name, model_name, is_classification=False, target_class=None):
    """
    åˆ†æICEå›¾ä¸­çš„å¼‚å¸¸ç‚¹åŠå…¶å¯¹åº”çš„å‚æ•°åŒºåŸŸ

    å‚æ•°:
    model: è®­ç»ƒå¥½çš„æ¨¡å‹
    X: ç‰¹å¾æ•°æ®
    feature_name: è¦åˆ†æçš„ç‰¹å¾å
    model_name: æ¨¡å‹åç§°
    is_classification: æ˜¯å¦ä¸ºåˆ†ç±»æ¨¡å‹
    target_class: åˆ†ç±»æ¨¡å‹çš„ç›®æ ‡ç±»åˆ«
    """

    print(f"  åˆ†æ{feature_name}çš„ICEå¼‚å¸¸ç‚¹...")

    # åˆ›å»ºå¼‚å¸¸åˆ†æå­ç›®å½•
    anomaly_dir = os.path.join(output_dir, "ice_anomaly_analysis")
    os.makedirs(anomaly_dir, exist_ok=True)

    # è·å–è¦åˆ†æçš„ç‰¹å¾ç´¢å¼•
    feature_idx = list(X.columns).index(feature_name)

    # ä½¿ç”¨æ›´å¯é çš„æ–¹æ³•è®¡ç®—ICEå’ŒPDP
    print(f"    ä½¿ç”¨sklearnçš„PartialDependenceDisplayè®¡ç®—ICEå’ŒPDP...")

    try:
        # ä½¿ç”¨sklearnçš„PartialDependenceDisplayè®¡ç®—ICEå’ŒPDP
        fig, ax = plt.subplots(figsize=(10, 7))

        if is_classification and target_class is not None:
            # åˆ†ç±»æ¨¡å‹
            disp = PartialDependenceDisplay.from_estimator(
                model, X, features=[feature_name],
                kind='both',
                target=target_class,
                ax=ax,
                pd_line_kw={"color": "red", "linewidth": 2},
                ice_lines_kw={"color": "blue", "alpha": 0.1, "linewidth": 0.5}
            )
        else:
            # å›å½’æ¨¡å‹
            disp = PartialDependenceDisplay.from_estimator(
                model, X, features=[feature_name],
                kind='both',
                ax=ax,
                pd_line_kw={"color": "red", "linewidth": 2},
                ice_lines_kw={"color": "blue", "alpha": 0.1, "linewidth": 0.5}
            )

        # ä»PartialDependenceDisplayå¯¹è±¡è·å–æ•°æ®
        # æ³¨æ„ï¼šsklearnçš„PartialDependenceDisplayå†…éƒ¨æ•°æ®ç»“æ„å¯èƒ½å› ç‰ˆæœ¬è€Œå¼‚
        # æˆ‘ä»¬éœ€è¦æ‰‹åŠ¨æå–ICEå’ŒPDPæ•°æ®

        # æ–¹æ³•1ï¼šå°è¯•ä»dispå¯¹è±¡è·å–æ•°æ®
        try:
            # å¯¹äºsklearn >= 1.0ç‰ˆæœ¬
            pdp_values = disp.pd_results[0]['average']
            ice_values = disp.pd_results[0]['individual']
            grid_points = disp.pd_results[0]['values'][0]
        except:
            # å¦‚æœä¸Šé¢çš„æ–¹æ³•å¤±è´¥ï¼Œä½¿ç”¨æ‰‹åŠ¨è®¡ç®—æ–¹æ³•
            print(f"    æ— æ³•ä»PartialDependenceDisplayæå–æ•°æ®ï¼Œä½¿ç”¨æ‰‹åŠ¨è®¡ç®—...")

            # ç”Ÿæˆç½‘æ ¼ç‚¹
            grid_resolution = min(50, len(np.unique(X.iloc[:, feature_idx])))
            grid_points = np.unique(X.iloc[:, feature_idx])
            if len(grid_points) > grid_resolution:
                # å¦‚æœå”¯ä¸€å€¼å¤ªå¤šï¼Œè¿›è¡Œé‡‡æ ·
                grid_points = np.linspace(X.iloc[:, feature_idx].min(),
                                          X.iloc[:, feature_idx].max(),
                                          grid_resolution)

            # æ‰‹åŠ¨è®¡ç®—ICEå€¼
            n_samples = min(200, len(X))
            if len(X) > n_samples:
                sample_indices = np.random.choice(len(X), n_samples, replace=False)
                X_sample = X.iloc[sample_indices].copy()
            else:
                sample_indices = np.arange(len(X))
                X_sample = X.copy()

            ice_values = []
            for i in range(len(X_sample)):
                if i % 50 == 0 and i > 0:
                    print(f"      æ­£åœ¨è®¡ç®—ICEå€¼ {i}/{len(X_sample)}...")

                ice_curve = []
                original_value = X_sample.iloc[i, feature_idx]

                for grid_point in grid_points:
                    X_temp = X_sample.copy()
                    X_temp.iloc[i, feature_idx] = grid_point

                    if is_classification:
                        if target_class is not None:
                            pred = model.predict_proba(X_temp.iloc[i:i + 1])[0, target_class]
                        else:
                            pred = model.predict_proba(X_temp.iloc[i:i + 1])[0, 0]  # é»˜è®¤ç¬¬ä¸€ä¸ªç±»åˆ«
                    else:
                        pred = model.predict(X_temp.iloc[i:i + 1])[0]

                    ice_curve.append(pred)

                ice_values.append(ice_curve)

            ice_values = np.array(ice_values)

            # è®¡ç®—PDPå€¼ï¼ˆICEå€¼çš„å¹³å‡å€¼ï¼‰
            pdp_values = ice_values.mean(axis=0)

        # ç¡®ä¿æ•°æ®å½¢çŠ¶æ­£ç¡®
        if ice_values.shape[1] != len(grid_points):
            print(f"    æ•°æ®å½¢çŠ¶ä¸åŒ¹é…: ice_values.shape={ice_values.shape}, grid_points.shape={grid_points.shape}")
            # å°è¯•è½¬ç½®ice_values
            if ice_values.shape[0] == len(grid_points):
                ice_values = ice_values.T
                print(f"    å·²è½¬ç½®ice_values: æ–°å½¢çŠ¶={ice_values.shape}")

        # ç°åœ¨è®¡ç®—å¼‚å¸¸ç‚¹
        if ice_values.shape[1] == len(grid_points) and len(pdp_values) == len(grid_points):
            # è®¡ç®—æ¯æ¡ICEæ›²çº¿ä¸PDPæ›²çº¿çš„å·®å¼‚
            ice_differences = np.abs(ice_values - pdp_values)
            max_differences = ice_differences.max(axis=1)  # æ¯ä¸ªæ ·æœ¬çš„æœ€å¤§å·®å¼‚
            mean_differences = ice_differences.mean(axis=1)  # æ¯ä¸ªæ ·æœ¬çš„å¹³å‡å·®å¼‚

            # ä½¿ç”¨Z-scoreè¯†åˆ«å¼‚å¸¸ICEæ›²çº¿
            z_scores = stats.zscore(max_differences)
            anomaly_threshold = 2.0  # Z-scoreé˜ˆå€¼
            anomaly_indices = np.where(np.abs(z_scores) > anomaly_threshold)[0]

            # ä½¿ç”¨IQRæ–¹æ³•è¯†åˆ«å¼‚å¸¸
            Q1 = np.percentile(max_differences, 25)
            Q3 = np.percentile(max_differences, 75)
            IQR = Q3 - Q1
            iqr_anomaly_indices = np.where(
                (max_differences < (Q1 - 1.5 * IQR)) |
                (max_differences > (Q3 + 1.5 * IQR))
            )[0]

            # åˆå¹¶ä¸¤ç§æ–¹æ³•æ£€æµ‹åˆ°çš„å¼‚å¸¸
            all_anomaly_indices = np.unique(np.concatenate([anomaly_indices, iqr_anomaly_indices]))

            print(f"    æ£€æµ‹åˆ° {len(all_anomaly_indices)} æ¡å¼‚å¸¸ICEæ›²çº¿")

            if len(all_anomaly_indices) > 0:
                # åˆ›å»ºå¼‚å¸¸åˆ†æå›¾
                create_anomaly_analysis_plot(
                    ice_values, pdp_values, grid_points, X_sample,
                    all_anomaly_indices, max_differences, mean_differences,
                    z_scores, anomaly_indices, iqr_anomaly_indices,
                    feature_name, model_name, anomaly_dir
                )

                # ä¿å­˜å¼‚å¸¸ç‚¹çš„è¯¦ç»†æ•°æ®
                save_anomaly_details(
                    X_sample, all_anomaly_indices, max_differences,
                    mean_differences, z_scores, anomaly_indices,
                    iqr_anomaly_indices, feature_name, model_name,
                    anomaly_dir, sample_indices
                )
            else:
                print(f"    æœªæ£€æµ‹åˆ°æ˜¾è‘—çš„ICEå¼‚å¸¸ç‚¹")

        plt.close(fig)  # å…³é—­ä¹‹å‰åˆ›å»ºçš„å›¾å½¢

    except Exception as e:
        print(f"    ICEå¼‚å¸¸ç‚¹åˆ†æå‡ºé”™: {e}")
        import traceback
        traceback.print_exc()

    return []


def create_anomaly_analysis_plot(ice_values, pdp_values, grid_points, X_sample,
                                 all_anomaly_indices, max_differences, mean_differences,
                                 z_scores, anomaly_indices, iqr_anomaly_indices,
                                 feature_name, model_name, anomaly_dir):
    """åˆ›å»ºå¼‚å¸¸ç‚¹åˆ†æå›¾"""

    fig, axes = plt.subplots(2, 3, figsize=(18, 12))
    fig.suptitle(f'{model_name} - ICE Anomaly Analysis for {feature_name}', fontsize=16)

    # 1. æ˜¾ç¤ºæ‰€æœ‰ICEæ›²çº¿ï¼Œé«˜äº®å¼‚å¸¸æ›²çº¿
    ax1 = axes[0, 0]
    for i in range(len(ice_values)):
        if i in all_anomaly_indices:
            ax1.plot(grid_points, ice_values[i], color='red', alpha=0.5, linewidth=1.0)
        else:
            ax1.plot(grid_points, ice_values[i], color='blue', alpha=0.1, linewidth=0.5)

    # ç»˜åˆ¶PDPæ›²çº¿
    ax1.plot(grid_points, pdp_values, color='black', linewidth=3, label='PDP')
    ax1.set_xlabel(feature_name)
    ax1.set_ylabel('Predicted Value')
    ax1.set_title(f'ICE Curves (Red=Anomalies, N={len(all_anomaly_indices)})')
    ax1.legend()
    ax1.grid(True, alpha=0.3)

    # 2. å¼‚å¸¸æ ·æœ¬çš„ç‰¹å¾åˆ†å¸ƒ
    ax2 = axes[0, 1]
    feature_idx = list(X_sample.columns).index(feature_name)
    all_values = X_sample.iloc[:, feature_idx].values
    anomaly_values = X_sample.iloc[all_anomaly_indices, feature_idx].values if len(all_anomaly_indices) > 0 else []

    # ç»˜åˆ¶æ‰€æœ‰æ ·æœ¬çš„åˆ†å¸ƒ
    ax2.hist(all_values, bins=30, alpha=0.5, color='blue', label='All Samples', density=True)
    # ç»˜åˆ¶å¼‚å¸¸æ ·æœ¬çš„åˆ†å¸ƒ
    if len(anomaly_values) > 0:
        ax2.hist(anomaly_values, bins=15, alpha=0.7, color='red', label='Anomalies', density=True)

    ax2.set_xlabel(feature_name)
    ax2.set_ylabel('Density')
    ax2.set_title(f'Feature Distribution of Anomalies')
    ax2.legend()
    ax2.grid(True, alpha=0.3)

    # 3. å¼‚å¸¸ç‚¹åœ¨ç‰¹å¾ç©ºé—´ä¸­çš„åˆ†å¸ƒ
    ax3 = axes[0, 2]
    other_features = [col for col in X_sample.columns if col != feature_name]
    if len(other_features) > 0 and len(all_anomaly_indices) > 0:
        other_feature = other_features[0]
        other_idx = list(X_sample.columns).index(other_feature)

        # ç»˜åˆ¶æ‰€æœ‰æ ·æœ¬
        ax3.scatter(X_sample.iloc[:, feature_idx], X_sample.iloc[:, other_idx],
                    alpha=0.3, color='blue', s=10, label='All Samples')
        # ç»˜åˆ¶å¼‚å¸¸æ ·æœ¬
        ax3.scatter(X_sample.iloc[all_anomaly_indices, feature_idx],
                    X_sample.iloc[all_anomaly_indices, other_idx],
                    alpha=0.8, color='red', s=50, label='Anomalies', edgecolors='black')

        ax3.set_xlabel(feature_name)
        ax3.set_ylabel(other_feature)
        ax3.set_title(f'Anomalies in Feature Space')
        ax3.legend()
        ax3.grid(True, alpha=0.3)
    else:
        ax3.text(0.5, 0.5, 'No anomalies or only one feature',
                 horizontalalignment='center', verticalalignment='center',
                 transform=ax3.transAxes, fontsize=12)
        ax3.set_title('Feature Space')
        ax3.axis('off')

    # 4. å¼‚å¸¸ç‚¹çš„ç»Ÿè®¡ç‰¹å¾åˆ†å¸ƒ
    ax4 = axes[1, 0]
    if len(all_anomaly_indices) > 0:
        normal_indices = np.setdiff1d(np.arange(len(X_sample)), all_anomaly_indices)

        if len(normal_indices) > 0:
            box_data = [max_differences[normal_indices], max_differences[all_anomaly_indices]]
            box_labels = ['Normal', 'Anomaly']

            bp = ax4.boxplot(box_data, labels=box_labels, patch_artist=True)
            bp['boxes'][0].set_facecolor('lightblue')
            bp['boxes'][1].set_facecolor('lightcoral')

            ax4.set_ylabel('Max ICE Difference from PDP')
            ax4.set_title('Statistical Difference: Normal vs Anomaly')
            ax4.grid(True, alpha=0.3)
        else:
            ax4.text(0.5, 0.5, 'Insufficient normal samples',
                     horizontalalignment='center', verticalalignment='center',
                     transform=ax4.transAxes, fontsize=12)
            ax4.set_title('Statistical Analysis')
            ax4.axis('off')
    else:
        ax4.text(0.5, 0.5, 'No anomalies detected',
                 horizontalalignment='center', verticalalignment='center',
                 transform=ax4.transAxes, fontsize=12)
        ax4.set_title('Statistical Analysis')
        ax4.axis('off')

    # 5. å¼‚å¸¸ç‚¹åœ¨ä¸åŒå‚æ•°åŒºé—´çš„åˆ†å¸ƒ
    ax5 = axes[1, 1]
    if len(all_anomaly_indices) > 0:
        n_bins = min(5, len(np.unique(all_values)))
        if n_bins > 1:
            bins = np.linspace(min(all_values), max(all_values), n_bins + 1)

            bin_counts = []
            anomaly_counts = []

            for i in range(n_bins):
                mask = (all_values >= bins[i]) & (all_values < bins[i + 1])
                if i == n_bins - 1:
                    mask = (all_values >= bins[i]) & (all_values <= bins[i + 1])

                total_in_bin = mask.sum()
                anomalies_in_bin = 0
                if len(all_anomaly_indices) > 0:
                    anomaly_mask = mask[all_anomaly_indices] if len(all_anomaly_indices) < len(mask) else mask
                    anomalies_in_bin = anomaly_mask.sum()

                bin_counts.append(total_in_bin)
                anomaly_counts.append(anomalies_in_bin)

            x_pos = np.arange(n_bins)
            width = 0.35

            ax5.bar(x_pos - width / 2, bin_counts, width, label='Total Samples', color='blue', alpha=0.6)
            ax5.bar(x_pos + width / 2, anomaly_counts, width, label='Anomalies', color='red', alpha=0.6)

            ax5.set_xlabel(f'{feature_name} Bins')
            ax5.set_ylabel('Count')
            ax5.set_title('Anomaly Distribution Across Feature Bins')
            ax5.set_xticks(x_pos)
            ax5.set_xticklabels([f'Bin {i + 1}' for i in range(n_bins)])
            ax5.legend()
            ax5.grid(True, alpha=0.3)
        else:
            ax5.text(0.5, 0.5, 'Insufficient unique values for binning',
                     horizontalalignment='center', verticalalignment='center',
                     transform=ax5.transAxes, fontsize=12)
            ax5.set_title('Binned Analysis')
            ax5.axis('off')
    else:
        ax5.text(0.5, 0.5, 'No anomalies detected',
                 horizontalalignment='center', verticalalignment='center',
                 transform=ax5.transAxes, fontsize=12)
        ax5.set_title('Binned Analysis')
        ax5.axis('off')

    # 6. å¼‚å¸¸ç‚¹ä¿¡æ¯å±•ç¤º
    ax6 = axes[1, 2]
    if len(all_anomaly_indices) > 0:
        # æ˜¾ç¤ºå¼‚å¸¸ç‚¹ç»Ÿè®¡ä¿¡æ¯
        info_text = f"Total anomalies: {len(all_anomaly_indices)}\n"
        info_text += f"Z-score anomalies: {len(anomaly_indices)}\n"
        info_text += f"IQR anomalies: {len(iqr_anomaly_indices)}\n\n"

        if len(all_anomaly_indices) <= 10:
            info_text += "Anomaly indices:\n"
            info_text += ", ".join([str(i) for i in all_anomaly_indices[:10]])
        else:
            info_text += f"Top 10 anomaly indices:\n"
            info_text += ", ".join([str(i) for i in all_anomaly_indices[:10]])

        ax6.text(0.1, 0.5, info_text, fontsize=11, verticalalignment='center')
        ax6.set_title('Anomaly Information')
        ax6.axis('off')
    else:
        ax6.text(0.5, 0.5, 'No anomalies detected',
                 horizontalalignment='center', verticalalignment='center',
                 transform=ax6.transAxes, fontsize=12)
        ax6.set_title('Anomaly Information')
        ax6.axis('off')

    plt.tight_layout()
    plt.savefig(f"{anomaly_dir}/{model_name}_anomaly_analysis_{feature_name}.png",
                dpi=300, bbox_inches="tight")
    plt.close()


def save_anomaly_details(X_sample, all_anomaly_indices, max_differences,
                         mean_differences, z_scores, anomaly_indices,
                         iqr_anomaly_indices, feature_name, model_name,
                         anomaly_dir, sample_indices):
    """ä¿å­˜å¼‚å¸¸ç‚¹è¯¦ç»†ä¿¡æ¯"""

    if len(all_anomaly_indices) > 0:
        anomaly_df = X_sample.iloc[all_anomaly_indices].copy()
        anomaly_df['max_ice_difference'] = max_differences[all_anomaly_indices]
        anomaly_df['mean_ice_difference'] = mean_differences[all_anomaly_indices]
        anomaly_df['z_score'] = z_scores[all_anomaly_indices]
        anomaly_df['is_iqr_anomaly'] = np.isin(all_anomaly_indices, iqr_anomaly_indices)

        # æ·»åŠ åŸå§‹æ ·æœ¬ç´¢å¼•
        anomaly_df['original_sample_index'] = sample_indices[all_anomaly_indices]

        anomaly_df.to_csv(f"{anomaly_dir}/{model_name}_anomaly_details_{feature_name}.csv", index=False)
        print(f"    å¼‚å¸¸ç‚¹è¯¦ç»†ä¿¡æ¯å·²ä¿å­˜åˆ°: {anomaly_dir}/{model_name}_anomaly_details_{feature_name}.csv")

        # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
        print(f"    {feature_name}å¼‚å¸¸ç‚¹çš„å‚æ•°ç»Ÿè®¡:")
        print(anomaly_df.describe())


# =====================================================================
#                 ç»˜åˆ¶PDPå’ŒICEå›¾çš„å‡½æ•°
# =====================================================================
def plot_pdp_ice(model, X, y, model_name, is_classification=False):
    """
    ç»˜åˆ¶PDPï¼ˆéƒ¨åˆ†ä¾èµ–å›¾ï¼‰å’ŒICEï¼ˆä¸ªä½“æ¡ä»¶æœŸæœ›å›¾ï¼‰

    å‚æ•°:
    model: è®­ç»ƒå¥½çš„æ¨¡å‹
    X: ç‰¹å¾æ•°æ®
    y: ç›®æ ‡å˜é‡
    model_name: æ¨¡å‹åç§°ï¼ˆç”¨äºä¿å­˜æ–‡ä»¶ï¼‰
    is_classification: æ˜¯å¦ä¸ºåˆ†ç±»æ¨¡å‹
    """

    print(f"\n===== ä¸º {model_name} ç”ŸæˆPDPå’ŒICEå›¾ =====")

    # ä¸ºPDP/ICEåˆ›å»ºå­ç›®å½•
    pdp_ice_dir = os.path.join(output_dir, "pdp_ice")
    os.makedirs(pdp_ice_dir, exist_ok=True)

    # è·å–ç‰¹å¾åç§°
    feature_names = X.columns.tolist()
    n_features = len(feature_names)

    # ===========================================================
    # å¯¹äºå›å½’æ¨¡å‹
    # ===========================================================
    if not is_classification:
        print(f"  ç”ŸæˆPDPå›¾...")

        # åˆ›å»ºå›¾å½¢
        fig, axes = plt.subplots(1, n_features, figsize=(5 * n_features, 5))

        if n_features == 1:
            axes = [axes]

        for i, feature in enumerate(feature_names):
            ax = axes[i]

            # ç»˜åˆ¶PDPå›¾
            PartialDependenceDisplay.from_estimator(
                model, X, features=[feature],
                ax=ax, line_kw={"color": "red", "linewidth": 2.5}
            )

            ax.set_xlabel(feature, fontsize=12)
            ax.set_ylabel('Partial Dependence', fontsize=12)
            ax.set_title(f'PDP for {feature}', fontsize=14)
            ax.grid(True, alpha=0.3)

        plt.tight_layout()
        plt.savefig(f"{pdp_ice_dir}/{model_name}_pdp.png", dpi=300, bbox_inches="tight")
        plt.close()

        # ===========================================================
        # ç»˜åˆ¶ICEå›¾å¹¶åˆ†æå¼‚å¸¸ç‚¹
        # ===========================================================
        print(f"  ç”ŸæˆICEå›¾å¹¶åˆ†æå¼‚å¸¸ç‚¹...")

        # å¯¹æ¯ä¸ªç‰¹å¾ç»˜åˆ¶ICEå›¾å¹¶åˆ†æå¼‚å¸¸ç‚¹
        for i, feature in enumerate(feature_names):
            try:
                # åˆ›å»ºå›¾å½¢
                fig, ax = plt.subplots(figsize=(10, 7))

                # è®¡ç®—PDPå’ŒICEå€¼
                disp = PartialDependenceDisplay.from_estimator(
                    model, X, features=[feature],
                    kind='both',
                    ax=ax,
                    pd_line_kw={"color": "red", "linewidth": 3, "label": "PDP"},
                    ice_lines_kw={"color": "blue", "alpha": 0.1, "linewidth": 0.5}
                )

                # æ·»åŠ å›¾ä¾‹
                ax.legend(fontsize=10)

                # æ·»åŠ æ ‡ç­¾å’Œæ ‡é¢˜
                ax.set_xlabel(feature, fontsize=12)
                ax.set_ylabel('Predicted Value', fontsize=12)
                ax.set_title(f'{model_name} - ICE Plot for {feature}', fontsize=14)
                ax.grid(True, alpha=0.3)

                # ä¿å­˜å›¾å½¢
                plt.tight_layout()
                plt.savefig(f"{pdp_ice_dir}/{model_name}_ice_{feature}.png",
                            dpi=300, bbox_inches="tight")
                plt.close()

                # åˆ†æè¯¥ç‰¹å¾çš„ICEå¼‚å¸¸ç‚¹
                analyze_ice_anomalies(model, X, feature, model_name, is_classification=False)

            except Exception as e:
                print(f"    ç»˜åˆ¶{feature}çš„ICEå›¾å‡ºé”™: {e}")
                import traceback
                traceback.print_exc()
                continue

        # ===========================================================
        # ç»˜åˆ¶æ‰€æœ‰ç‰¹å¾çš„ICEå›¾ï¼ˆå­å›¾å½¢å¼ï¼‰
        # ===========================================================
        print(f"  ç”Ÿæˆç»„åˆICEå›¾...")

        try:
            fig, axes = plt.subplots(1, n_features, figsize=(5 * n_features, 5))

            if n_features == 1:
                axes = [axes]

            for i, feature in enumerate(feature_names):
                ax = axes[i]

                # å›å½’æ¨¡å‹
                PartialDependenceDisplay.from_estimator(
                    model, X, features=[feature],
                    kind='both',
                    ax=ax,
                    pd_line_kw={"color": "red", "linewidth": 2.5},
                    ice_lines_kw={"color": "blue", "alpha": 0.15, "linewidth": 0.6}
                )

                ax.set_xlabel(feature, fontsize=11)
                ax.set_ylabel('Predicted Value', fontsize=11)
                ax.set_title(f'ICE for {feature}', fontsize=12)
                ax.grid(True, alpha=0.3)

            plt.tight_layout()
            plt.savefig(f"{pdp_ice_dir}/{model_name}_ice_combined.png",
                        dpi=300, bbox_inches="tight")
            plt.close()
        except Exception as e:
            print(f"    ç”Ÿæˆç»„åˆICEå›¾å‡ºé”™: {e}")

    # ===========================================================
    # å¯¹äºåˆ†ç±»æ¨¡å‹
    # ===========================================================
    else:
        # è·å–ç±»åˆ«æ•°é‡
        unique_classes = np.unique(y)
        n_classes = len(unique_classes)
        print(f"  åˆ†ç±»æ¨¡å‹æœ‰ {n_classes} ä¸ªç±»åˆ«")

        # ä¸ºæ¯ä¸ªç±»åˆ«ç”ŸæˆPDPå›¾
        print(f"  ä¸ºæ¯ä¸ªç±»åˆ«ç”ŸæˆPDPå›¾...")

        for class_idx in unique_classes:
            fig, axes = plt.subplots(1, n_features, figsize=(5 * n_features, 5))

            if n_features == 1:
                axes = [axes]

            for i, feature in enumerate(feature_names):
                ax = axes[i]

                # ç»˜åˆ¶PDPå›¾ï¼ŒæŒ‡å®šç›®æ ‡ç±»åˆ«
                try:
                    PartialDependenceDisplay.from_estimator(
                        model, X, features=[feature],
                        target=class_idx,
                        ax=ax, line_kw={"color": "red", "linewidth": 2.5}
                    )
                except Exception as e:
                    print(f"    è­¦å‘Š: æ— æ³•ä¸ºç±»åˆ« {class_idx} ç»˜åˆ¶PDPå›¾: {e}")
                    continue

                # æ·»åŠ æ ‡ç­¾å’Œæ ‡é¢˜
                ax.set_xlabel(feature, fontsize=12)
                ax.set_ylabel('Partial Dependence', fontsize=12)
                ax.set_title(f'PDP for {feature} (Class {class_idx})', fontsize=14)
                ax.grid(True, alpha=0.3)

            plt.tight_layout()
            plt.savefig(f"{pdp_ice_dir}/{model_name}_pdp_class_{class_idx}.png",
                        dpi=300, bbox_inches="tight")
            plt.close()

        # ä¸ºæ¯ä¸ªç±»åˆ«å’Œæ¯ä¸ªç‰¹å¾ç»˜åˆ¶ICEå›¾
        print(f"  ä¸ºæ¯ä¸ªç±»åˆ«ç”ŸæˆICEå›¾...")

        for class_idx in unique_classes:
            for feature in feature_names:
                # åˆ›å»ºå›¾å½¢
                fig, ax = plt.subplots(figsize=(10, 7))

                try:
                    # è®¡ç®—PDPå’ŒICEå€¼
                    PartialDependenceDisplay.from_estimator(
                        model, X, features=[feature],
                        kind='both',
                        target=class_idx,
                        ax=ax,
                        pd_line_kw={"color": "red", "linewidth": 3, "label": "PDP"},
                        ice_lines_kw={"color": "blue", "alpha": 0.1, "linewidth": 0.5}
                    )

                    # æ·»åŠ å›¾ä¾‹
                    ax.legend(fontsize=10)

                    # æ·»åŠ æ ‡ç­¾å’Œæ ‡é¢˜
                    ax.set_xlabel(feature, fontsize=12)
                    ax.set_ylabel('Predicted Probability', fontsize=12)
                    ax.set_title(f'{model_name} - ICE Plot for {feature} (Class {class_idx})',
                                 fontsize=14)
                    ax.grid(True, alpha=0.3)

                    # ä¿å­˜å›¾å½¢
                    plt.tight_layout()
                    plt.savefig(f"{pdp_ice_dir}/{model_name}_ice_{feature}_class_{class_idx}.png",
                                dpi=300, bbox_inches="tight")
                    plt.close()

                except Exception as e:
                    print(f"    è­¦å‘Š: æ— æ³•ä¸ºç±»åˆ« {class_idx} å’Œç‰¹å¾ {feature} ç»˜åˆ¶ICEå›¾: {e}")

        # ä¸ºæ¯ä¸ªç±»åˆ«ç»˜åˆ¶ç»„åˆICEå›¾
        print(f"  ç”Ÿæˆç»„åˆICEå›¾...")

        for class_idx in unique_classes:
            fig, axes = plt.subplots(1, n_features, figsize=(5 * n_features, 5))

            if n_features == 1:
                axes = [axes]

            for i, feature in enumerate(feature_names):
                ax = axes[i]

                try:
                    # åˆ†ç±»æ¨¡å‹ï¼šç»˜åˆ¶æŒ‡å®šç±»åˆ«çš„ICEå›¾
                    PartialDependenceDisplay.from_estimator(
                        model, X, features=[feature],
                        kind='both',
                        target=class_idx,
                        ax=ax,
                        pd_line_kw={"color": "red", "linewidth": 2.5},
                        ice_lines_kw={"color": "blue", "alpha": 0.15, "linewidth": 0.6}
                    )

                    ax.set_xlabel(feature, fontsize=11)
                    ax.set_ylabel('Predicted Probability', fontsize=11)
                    ax.set_title(f'ICE for {feature} (Class {class_idx})', fontsize=12)
                    ax.grid(True, alpha=0.3)

                except Exception as e:
                    print(f"    è­¦å‘Š: æ— æ³•ä¸ºç±»åˆ« {class_idx} ç»˜åˆ¶ç»„åˆICEå›¾: {e}")

            plt.tight_layout()
            plt.savefig(f"{pdp_ice_dir}/{model_name}_ice_combined_class_{class_idx}.png",
                        dpi=300, bbox_inches="tight")
            plt.close()

    print(f"  PDPå’ŒICEå›¾å·²ä¿å­˜åˆ° {pdp_ice_dir}")


# =====================================================================
#                 é€šç”¨æ¨¡å‹ + SHAP è¿è¡Œå‡½æ•°
# =====================================================================
def run_model_and_shap(model, X, y, name, is_classification=False):
    print(f"\n===== è¿è¡Œæ¨¡å‹ï¼š{name} =====")

    # è®­ç»ƒåˆ‡åˆ†
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, train_size=0.8, shuffle=True, random_state=0
    )

    # 5 æŠ˜äº¤å‰éªŒè¯
    cv_score = cross_val_score(model, X, y, cv=5)
    print(f"CV Mean Score = {cv_score.mean()}")

    # æ¨¡å‹è®­ç»ƒ
    model.fit(X_train, y_train)

    # SHAP
    try:
        explainer = shap.TreeExplainer(model)
        shap_raw = explainer.shap_values(X)

        # ===========================================================
        #           å›å½’ï¼šshap_raw æ˜¯ numpy æ•°ç»„
        #           åˆ†ç±»ï¼šshap_raw æ˜¯ listï¼Œæ¯ç±»ä¸€ä¸ªæ•°ç»„
        # ===========================================================
        if is_classification:
            # shap_raw æ˜¯ list
            num_classes = len(shap_raw)

            # ä¿å­˜åŸå§‹ list SHAP
            np.save(f"{output_dir}/{name}_shap_raw.npy", shap_raw, allow_pickle=True)

            # æ¯ä¸ªç±»åˆ«ä¿å­˜å•ç‹¬ CSV
            for cls in range(num_classes):
                df_cls = pd.DataFrame(shap_raw[cls], columns=X.columns)
                df_cls.to_csv(f"{output_dir}/{name}_shap_values_class_{cls}.csv", index=False)

            # ç”¨å‡å€¼ä½œä¸º overall shap
            shap_values = np.mean(np.array(shap_raw), axis=0)

        else:
            # å›å½’ç›´æ¥äºŒç»´
            shap_values = shap_raw
            pd.DataFrame(shap_values, columns=X.columns).to_csv(
                f"{output_dir}/{name}_shap_values.csv", index=False
            )

        # ===========================================================
        #   1. æ€»ä½“ SHAP summary å›¾
        # ===========================================================
        plt.figure()
        shap.summary_plot(shap_values, X, show=False)
        plt.title(f"{name} - SHAP Summary (Overall)")
        plt.savefig(f"{output_dir}/{name}_summary_overall.png", dpi=300, bbox_inches="tight")
        plt.close()

        # ===========================================================
        #   2. æ€»ä½“ bar plot
        # ===========================================================
        plt.figure()
        shap.summary_plot(shap_values, X, plot_type="bar", show=False)
        plt.title(f"{name} - SHAP Bar Plot")
        plt.savefig(f"{output_dir}/{name}_bar_overall.png", dpi=300, bbox_inches="tight")
        plt.close()

        # ===========================================================
        #   3. æ€»ä½“ heatmap
        # ===========================================================
        plt.figure(figsize=(6, 4))
        shap_mean = np.abs(shap_values).mean(axis=0)
        plt.imshow(shap_mean.reshape(1, -1), aspect="auto", cmap="viridis")
        plt.xticks(range(len(X.columns)), X.columns, rotation=45)
        plt.yticks([])
        plt.title(f"{name} - SHAP Heatmap")
        plt.colorbar()
        plt.savefig(f"{output_dir}/{name}_heatmap_overall.png", dpi=300, bbox_inches="tight")
        plt.close()

        # ===========================================================
        #   4. æ€»ä½“ dependence plot - ä½¿ç”¨å•è‰²
        # ===========================================================
        for feat in X.columns:
            plt.figure(figsize=(8, 6))

            # ä½¿ç”¨ matplotlib ç›´æ¥ç»˜åˆ¶å•è‰²æ•£ç‚¹å›¾
            feature_idx = X.columns.get_loc(feat)
            plt.scatter(X.iloc[:, feature_idx], shap_values[:, feature_idx],
                        alpha=0.7, color='blue', s=20)
            plt.xlabel(feat, fontsize=12)
            plt.ylabel('SHAP value', fontsize=12)
            plt.title(f"{name} - SHAP Dependence ({feat})", fontsize=14)
            plt.grid(True, alpha=0.3)

            plt.savefig(f"{output_dir}/{name}_dependence_{feat}.png", dpi=300, bbox_inches="tight")
            plt.close()

        # ===========================================================
        #   5. äº¤äº’çŸ©é˜µå›¾ï¼ˆå›å½’æ¨¡å‹å’Œåˆ†ç±»æ¨¡å‹éƒ½ä½¿ç”¨æ€»ä½“SHAPå€¼ï¼‰
        # ===========================================================
        try:
            # å°è¯•è·å–äº¤äº’å€¼
            if not is_classification:
                inter = explainer.shap_interaction_values(X)
                mean_inter = np.abs(inter).mean(axis=0)
            else:
                # å¯¹äºåˆ†ç±»æ¨¡å‹ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªç±»åˆ«çš„äº¤äº’å€¼ä½œä¸ºæ€»ä½“
                inter = explainer.shap_interaction_values(X)[0]
                mean_inter = np.abs(inter).mean(axis=0)

            plt.figure(figsize=(8, 6))
            im = plt.imshow(mean_inter, cmap="viridis")
            plt.colorbar(im)
            plt.xticks(range(len(X.columns)), X.columns, rotation=45)
            plt.yticks(range(len(X.columns)), X.columns)
            plt.title(f"{name} - SHAP Interaction Matrix")
            plt.savefig(f"{output_dir}/{name}_interaction_matrix.png",
                        dpi=300, bbox_inches="tight")
            plt.close()
        except Exception as e:
            print(f"æ— æ³•ç”Ÿæˆäº¤äº’çŸ©é˜µå›¾: {e}")

    except Exception as e:
        print(f"SHAPåˆ†æå‡ºé”™: {e}")
        import traceback
        traceback.print_exc()

    # ===========================================================
    #   6. ç»˜åˆ¶PDPå’ŒICEå›¾ï¼Œå¹¶åˆ†æå¼‚å¸¸ç‚¹
    # ===========================================================
    plot_pdp_ice(model, X, y, name, is_classification)

    print(f"SHAP å’Œ PDP/ICE åˆ†æå·²å®Œæˆï¼š{name}")


# =============================
#     è¿è¡Œä¸‰ä¸ªæ¨¡å‹
# =============================
print("=" * 50)
print("å¼€å§‹æ¨¡å‹è®­ç»ƒå’Œå¯è§£é‡Šæ€§åˆ†æ")
print("=" * 50)

try:
    reg_depth = XGBRegressor(**params)
    run_model_and_shap(reg_depth, X, y_depth, "MeltPool_Depth")
except Exception as e:
    print(f"MeltPool_Depthæ¨¡å‹åˆ†æå‡ºé”™: {e}")
    import traceback

    traceback.print_exc()

try:
    reg_rough = XGBRegressor(**params)
    run_model_and_shap(reg_rough, X, y_rough, "Surface_Roughness")
except Exception as e:
    print(f"Surface_Roughnessæ¨¡å‹åˆ†æå‡ºé”™: {e}")
    import traceback

    traceback.print_exc()

try:
    clf_pore = XGBClassifier(**params, use_label_encoder=False, eval_metric='mlogloss')
    run_model_and_shap(clf_pore, X, y_pore_encoded, "Pore_Type", is_classification=True)
except Exception as e:
    print(f"Pore_Typeæ¨¡å‹åˆ†æå‡ºé”™: {e}")
    import traceback

    traceback.print_exc()

print(f"\n" + "=" * 50)
print(f"ğŸ‰ å…¨éƒ¨æ¨¡å‹ä¸ SHAPã€PDPã€ICE å›¾ç”Ÿæˆå®Œæ¯•ï¼")
print(f"ğŸ“ æ‰€æœ‰è¾“å‡ºä¿å­˜åœ¨: {output_dir}/")
print(f"ğŸ“Š è¾“å‡ºå†…å®¹åŒ…æ‹¬:")
print(f"   - SHAP åˆ†æå›¾ï¼ˆsummary, bar, heatmap, dependence, interactionï¼‰")
print(f"   - PDP å›¾ï¼ˆéƒ¨åˆ†ä¾èµ–å›¾ï¼‰")
print(f"   - ICE å›¾ï¼ˆä¸ªä½“æ¡ä»¶æœŸæœ›å›¾ï¼‰")
print(f"   - ICEå¼‚å¸¸ç‚¹åˆ†æå›¾å’Œè¯¦ç»†æ•°æ®")
print(f"   - æ¯ä¸ªç‰¹å¾çš„å•ç‹¬ICEå›¾")
print(f"   - æ‰€æœ‰ç‰¹å¾çš„ç»„åˆICEå›¾")
print(f"   - åˆ†ç±»æ¨¡å‹ä¸ºæ¯ä¸ªç±»åˆ«å•ç‹¬ç”ŸæˆPDP/ICEå›¾")
print(f"ğŸ“ˆ ICEå¼‚å¸¸ç‚¹åˆ†æåŒ…æ‹¬:")
print(f"   1. å¼‚å¸¸ICEæ›²çº¿å¯è§†åŒ–")
print(f"   2. å¼‚å¸¸ç‚¹å‚æ•°åˆ†å¸ƒåˆ†æ")
print(f"   3. å¼‚å¸¸ç‚¹åœ¨ç‰¹å¾ç©ºé—´ä¸­çš„åˆ†å¸ƒ")
print(f"   4. å¼‚å¸¸ç‚¹ç»Ÿè®¡ç‰¹å¾åˆ†æ")
print(f"   5. å¼‚å¸¸ç‚¹åœ¨ä¸åŒå‚æ•°åŒºé—´çš„åˆ†å¸ƒ")
print(f"   6. å¼‚å¸¸ç‚¹çš„è¯¦ç»†å‚æ•°è¡¨æ ¼")
print("=" * 50)